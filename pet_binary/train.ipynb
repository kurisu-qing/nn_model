{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ea87bb",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77b4dc5-58bd-46b9-a011-6cffc180b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e474838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(df, path):\n",
    "    df['label'] = 2\n",
    "    path = path.rstrip('.csv')\n",
    "    path = f'{path}.txt'\n",
    "    with open(path, 'r') as fr:\n",
    "        lines = fr.readlines()\n",
    "        for i, line in enumerate(lines[:-1]):\n",
    "            line = line.rstrip('\\n').split(',')\n",
    "            j, l = int(line[0]), int(line[1])\n",
    "            k = int(lines[i+1].split(',')[0]) - 1\n",
    "            if k<j:\n",
    "                print(k)\n",
    "            df.loc[j:k, 'label'] = l\n",
    "\n",
    "        line = lines[-1].rstrip('\\n').split(',')\n",
    "        j, l = int(line[0]), int(line[1])\n",
    "        df.loc[j:, 'label'] = 1\n",
    "\n",
    "\n",
    "def process_feature(df):\n",
    "    df['ln_pts'] = np.log(df['pts']+1)\n",
    "    df['ln_dyn'] = np.log(df['pts_dyn']+1)\n",
    "    df['ln_sta'] = np.log(df['pts']-df['pts_dyn']+1)\n",
    "\n",
    "    df['z_iqr'] = df['z_q3'] - df['z_q1']\n",
    "\n",
    "    df['range'] = np.sqrt(np.square(df['x_c'])+np.square(df['y_c']))\n",
    "\n",
    "    df['dx'] = df['x_c'].diff().fillna(0)\n",
    "    df['dy'] = df['y_c'].diff().fillna(0)\n",
    "    df['dist'] = np.sqrt(np.square(df['dx'])+np.square(df['dy']))\n",
    "\n",
    "    df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f66631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATR_GN_P2-240527-30019-2025-08-31-00-1384880-1388055.csv 24 98.1%\n",
      "ATR_GN_P2-240527-30019-2025-09-02-00-3097855-3098844.csv 8 98.0%\n",
      "ATR_GN_P2-240527-30019-2025-09-02-09-3427349-3428726.csv 7 100.0%\n",
      "ATR_GN_P2-240601-00069-2025-08-27-15-181634-185130.csv 28 77.2%\n",
      "ATR_GN_P2-240601-00069-2025-08-29-04-713100-716599.csv 29 98.6%\n",
      "ATR_GN_P4-241029-00016-2025-09-01-07-2584784-2591384.csv 49 97.7%\n",
      "ATR_GN_P4-250120-00138-2025-09-04-15-372127-373946.csv 14 95.0%\n",
      "ATR_GN_P4-250120-00138-2025-09-07-15-2969150-2970732.csv 13 99.1%\n",
      "ATR_GN_P4-250120-00138-2025-09-07-20-3155534-3159779.csv 20 7.1%\n",
      "ATR_GN_P4-250120-00172-2025-09-01-03-7698018-7703053.csv 18 100.0%\n",
      "P1-TP5-0528test-170695-173549.csv 17 99.8%\n",
      "P1-TP5-0528test-199959-202507.csv 12 95.8%\n",
      "P1-TP5-0528test-203583-205322.csv 13 99.4%\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for path in iglob(r'C:/Users/pontosense/Downloads/Target/*.csv'):\n",
    "    path = path.replace('\\\\', '/')\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "\n",
    "    process_label(df, path)\n",
    "    process_feature(df)\n",
    "\n",
    "    n = round(df.shape[0] / 120)\n",
    "    print(path.split('/')[-1], n, '{:.1%}'.format(df['label'].mean()))\n",
    "\n",
    "    df = df[\n",
    "        ['ln_pts', 'z_iqr', 'z_std', 'z_c', 'range', 'l_r', 's_r', 'dist', 'label']\n",
    "    ].astype('float32').values\n",
    "    for i in range(n):\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c9196",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c77b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f2cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dfs):\n",
    "        self.dfs = dfs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dfs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = self.dfs[idx]\n",
    "        jdx = np.random.choice(arr.shape[0]-79, 1)[0]\n",
    "        batch = arr[jdx:jdx+80, :-1]\n",
    "        label = arr[jdx:jdx+80, -1]\n",
    "        return batch, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8b532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2025)\n",
    "torch.manual_seed(2025)\n",
    "\n",
    "train_ds = TrainDataset(dfs)\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00558a6a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608d84ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "from layers import (\n",
    "    EMA,\n",
    "    Transpose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b870088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Sequential                               [2, 80, 8]                [2, 80, 1]                --\n",
       "├─Linear: 1-1                            [2, 80, 8]                [2, 80, 64]               512\n",
       "├─Transpose: 1-2                         [2, 80, 64]               [2, 64, 80]               --\n",
       "├─ReLU6: 1-3                             [2, 64, 80]               [2, 64, 80]               --\n",
       "├─EMA: 1-4                               [2, 64, 80]               [2, 64, 80]               128\n",
       "├─Transpose: 1-5                         [2, 64, 80]               [2, 80, 64]               --\n",
       "├─ReLU6: 1-6                             [2, 80, 64]               [2, 80, 64]               --\n",
       "├─Linear: 1-7                            [2, 80, 64]               [2, 80, 1]                64\n",
       "===================================================================================================================\n",
       "Total params: 704\n",
       "Trainable params: 704\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.17\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.17\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = 64\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, hs, bias=False),\n",
    "    Transpose(),\n",
    "    nn.ReLU6(),\n",
    "    EMA(hs, length=80),\n",
    "    Transpose(),\n",
    "    nn.ReLU6(),\n",
    "    nn.Linear(hs, 1, bias=False)\n",
    ")\n",
    "\n",
    "summary(model, (2, 80, 8), col_names=['input_size', 'output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab1e2d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7eb6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy,\n",
    "    BinaryAUROC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c49c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=.1**.5)\n",
    "\n",
    "metric = MetricCollection({'acc':BinaryAccuracy(), 'auc':BinaryAUROC()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e8228e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2 - acc: 0.8711 - auc: 0.6147\n",
      "epoch 12 - acc: 0.8862 - auc: 0.8282\n",
      "epoch 22 - acc: 0.8822 - auc: 0.8867\n",
      "epoch 32 - acc: 0.8844 - auc: 0.9139\n",
      "epoch 42 - acc: 0.8877 - auc: 0.9166\n",
      "epoch 52 - acc: 0.8987 - auc: 0.9286\n",
      "epoch 62 - acc: 0.9192 - auc: 0.9353\n",
      "epoch 72 - acc: 0.9207 - auc: 0.9365\n",
      "epoch 82 - acc: 0.9321 - auc: 0.9369\n",
      "epoch 92 - acc: 0.9361 - auc: 0.9420\n",
      "epoch 102 - acc: 0.9406 - auc: 0.9466\n",
      "epoch 112 - acc: 0.9409 - auc: 0.9463\n",
      "epoch 122 - acc: 0.9405 - auc: 0.9453\n",
      "epoch 132 - acc: 0.9378 - auc: 0.9338\n",
      "epoch 142 - acc: 0.9384 - auc: 0.9434\n",
      "epoch 152 - acc: 0.9394 - auc: 0.9473\n",
      "epoch 162 - acc: 0.9405 - auc: 0.9454\n",
      "epoch 172 - acc: 0.9389 - auc: 0.9419\n",
      "epoch 182 - acc: 0.9344 - auc: 0.9404\n",
      "epoch 192 - acc: 0.9448 - auc: 0.9513\n",
      "epoch 202 - acc: 0.9438 - auc: 0.9419\n",
      "epoch 212 - acc: 0.9393 - auc: 0.9475\n",
      "epoch 222 - acc: 0.9492 - auc: 0.9501\n",
      "epoch 232 - acc: 0.9395 - auc: 0.9394\n",
      "epoch 242 - acc: 0.9396 - auc: 0.9447\n",
      "epoch 252 - acc: 0.9381 - auc: 0.9433\n",
      "epoch 262 - acc: 0.9405 - auc: 0.9521\n",
      "epoch 272 - acc: 0.9332 - auc: 0.9426\n",
      "epoch 282 - acc: 0.9398 - auc: 0.9489\n",
      "epoch 292 - acc: 0.9416 - auc: 0.9485\n",
      "epoch 300 - acc: 0.9459 - auc: 0.9490\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "step = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for batch, label in train_dl:\n",
    "        logit = model(batch).squeeze(-1)\n",
    "        loss = loss_fn(logit, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        proba = torch.sigmoid(logit)\n",
    "        metric.update(proba, label)\n",
    "        step += 1\n",
    "    scheduler.step()\n",
    "\n",
    "    if (epoch % 10 == 1) or (epoch==epochs-1):\n",
    "        res = metric.compute()\n",
    "        print(f'epoch {epoch+1:>2d} - acc: {res[\"acc\"]:.4f} - auc: {res[\"auc\"]:.4f}')\n",
    "        metric.reset()\n",
    "        torch.save(model.state_dict(), f'./ckpt/epoch{epoch}-{res[\"auc\"]:.4f}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68346dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=8, out_features=64, bias=False)\n",
       "  (1): Transpose()\n",
       "  (2): ReLU6()\n",
       "  (3): EMA(in_chn=64, length=80)\n",
       "  (4): Transpose()\n",
       "  (5): ReLU6()\n",
       "  (6): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a3628ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0552, 0.4516, 0.4204, 0.0735, 0.0100, 0.2558, 0.1382, 0.0104, 0.8001,\n",
       "        0.1398, 0.9042, 0.7046, 0.0100, 0.0909, 0.9341, 0.3078, 0.0100, 0.2093,\n",
       "        0.1412, 0.5658, 0.0136, 0.1505, 0.2014, 0.6369, 0.1727, 0.7603, 0.0100,\n",
       "        0.1473, 0.8202, 0.4745, 0.2965, 0.6796, 0.3235, 0.9530, 0.1374, 0.7407,\n",
       "        0.0100, 0.0491, 0.5837, 0.6580, 0.3492, 0.1696, 0.0100, 0.1417, 0.0100,\n",
       "        0.0100, 0.2849, 0.8315, 0.3609, 0.1565, 0.7086, 0.7284, 0.9117, 0.0138,\n",
       "        0.8856, 0.5010, 0.2206, 0.3838, 0.3552, 0.5857, 0.8184, 0.3391, 0.0100,\n",
       "        0.7613])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[3].alpha.data.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720bd2f5",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c942a7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATR_GN_P2-240527-30019-2025-09-02-01-3123914-3124287.csv 4 100.0%\n",
      "ATR_GN_P2-240527-30019-2025-09-03-11-4351701-4352882.csv 4 31.6%\n",
      "P1-TP5-0528test-185780-186966.csv 11 100.0%\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for path in iglob(r'C:/Users/pontosense/Downloads/Target/test/*.csv'):\n",
    "    path = path.replace('\\\\', '/')\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "\n",
    "    process_label(df, path)\n",
    "    process_feature(df)\n",
    "\n",
    "    n = df.shape[0] // 80\n",
    "    print(path.split('/')[-1], n, '{:.1%}'.format(df['label'].mean()))\n",
    "\n",
    "    df = df[\n",
    "        ['ln_pts', 'z_iqr', 'z_std', 'z_c', 'range', 'l_r', 's_r', 'dist', 'label']\n",
    "    ].astype('float32').values\n",
    "    for i in range(n):\n",
    "        dfs.append(df[i*80:(i+1)*80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae44c2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fe8da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dfs):\n",
    "        self.dfs = dfs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dfs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = self.dfs[idx]\n",
    "        batch = arr[:, :-1]\n",
    "        label = arr[:, -1]\n",
    "        return batch, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55cfb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = TestDataset(dfs)\n",
    "test_dl = DataLoader(test_ds, batch_size=4, shuffle=False, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab00e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1-0.6147.pth  - acc: 0.8401 - auc: 0.8743\n",
      "epoch101-0.9466.pth  - acc: 0.9289 - auc: 0.8963\n",
      "epoch11-0.8282.pth  - acc: 0.8401 - auc: 0.9040\n",
      "epoch111-0.9463.pth  - acc: 0.9289 - auc: 0.8964\n",
      "epoch121-0.9453.pth  - acc: 0.9276 - auc: 0.8954\n",
      "epoch131-0.9338.pth  - acc: 0.9283 - auc: 0.8956\n",
      "epoch141-0.9434.pth  - acc: 0.9316 - auc: 0.8949\n",
      "epoch151-0.9473.pth  - acc: 0.9316 - auc: 0.8948\n",
      "epoch161-0.9454.pth  - acc: 0.9309 - auc: 0.8946\n",
      "epoch171-0.9419.pth  - acc: 0.9303 - auc: 0.8946\n",
      "epoch181-0.9404.pth  - acc: 0.9296 - auc: 0.8946\n",
      "epoch191-0.9513.pth  - acc: 0.9303 - auc: 0.8946\n",
      "epoch201-0.9419.pth  - acc: 0.9303 - auc: 0.8947\n",
      "epoch21-0.8867.pth  - acc: 0.8401 - auc: 0.9330\n",
      "epoch211-0.9475.pth  - acc: 0.9303 - auc: 0.8946\n",
      "epoch221-0.9501.pth  - acc: 0.9303 - auc: 0.8948\n",
      "epoch231-0.9394.pth  - acc: 0.9296 - auc: 0.8948\n",
      "epoch241-0.9447.pth  - acc: 0.9303 - auc: 0.8948\n",
      "epoch251-0.9433.pth  - acc: 0.9296 - auc: 0.8948\n",
      "epoch261-0.9521.pth  - acc: 0.9303 - auc: 0.8947\n",
      "epoch271-0.9426.pth  - acc: 0.9303 - auc: 0.8947\n",
      "epoch281-0.9489.pth  - acc: 0.9303 - auc: 0.8947\n",
      "epoch291-0.9485.pth  - acc: 0.9303 - auc: 0.8947\n",
      "epoch299-0.9490.pth  - acc: 0.9303 - auc: 0.8947\n",
      "epoch31-0.9139.pth  - acc: 0.8401 - auc: 0.9272\n",
      "epoch41-0.9166.pth  - acc: 0.8454 - auc: 0.9179\n",
      "epoch51-0.9286.pth  - acc: 0.8961 - auc: 0.9062\n",
      "epoch61-0.9353.pth  - acc: 0.9026 - auc: 0.9032\n",
      "epoch71-0.9365.pth  - acc: 0.9125 - auc: 0.8977\n",
      "epoch81-0.9369.pth  - acc: 0.9158 - auc: 0.8983\n",
      "epoch91-0.9420.pth  - acc: 0.9276 - auc: 0.8964\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for path in iglob('ckpt/*.pth'):\n",
    "    ckpt = torch.load(path)\n",
    "    model.load_state_dict(ckpt)\n",
    "    s = path.split('\\\\')[-1]\n",
    "\n",
    "    for batch, label in test_dl:\n",
    "        with torch.no_grad():\n",
    "            logit = model(batch).squeeze(-1)\n",
    "            proba = torch.sigmoid(logit)\n",
    "\n",
    "        metric.update(proba, label)\n",
    "\n",
    "    res = metric.compute()\n",
    "    print(f'{s}  - acc: {res[\"acc\"]:.4f} - auc: {res[\"auc\"]:.4f}')\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfeaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "path = 'ckpt/epoch21-0.8867.pth'\n",
    "ckpt = torch.load(path)\n",
    "s = path.split('//')[-1]\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "probas = []\n",
    "labels = []\n",
    "for batch, label in test_dl:\n",
    "    with torch.no_grad():\n",
    "        logit = model(batch).squeeze(-1)\n",
    "        proba = torch.sigmoid(logit)\n",
    "\n",
    "    labels.append(label.flatten().numpy())\n",
    "    probas.append(proba.flatten().numpy())\n",
    "    metric.update(proba, label)\n",
    "    break\n",
    "\n",
    "# res = metric.compute()\n",
    "# print(f'{s}  - acc: {res[\"acc\"]:.4f} - auc: {res[\"auc\"]:.4f}')\n",
    "# metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e72926c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9512436 , 0.4121284 , 0.57202524, 0.9942352 , 0.38036877,\n",
       "       0.11640994, 0.07208236, 0.08725858], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e30c7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3988, 2.5763, 3.1042, 3.0979, 2.9816, 2.9710, 3.0804, 3.0413, 3.1472,\n",
       "        3.0080, 2.8196, 2.8772, 2.8212, 2.7985, 2.7628, 2.7143, 2.5950, 2.8100,\n",
       "        2.7257, 2.5937, 2.5216, 2.8997, 3.0910, 2.8126, 3.1184, 2.7823, 2.6153,\n",
       "        2.6994, 2.6169, 2.7610, 2.7248, 2.7025, 2.6632, 2.5674, 2.6755, 2.9374,\n",
       "        2.7991, 2.8609, 2.8261, 2.9362, 2.8920, 2.8185, 2.7370, 2.7926, 2.7865,\n",
       "        3.2422, 3.1860, 2.7271, 2.9050, 2.5613, 2.6024, 2.6309, 2.5244, 2.4070,\n",
       "        2.4062, 2.5203, 2.3529, 2.5255, 2.4612, 2.8329, 2.8527, 2.4304, 2.8247,\n",
       "        2.8194, 2.7688, 2.4443, 2.2603, 2.4704, 2.4080, 2.4878, 2.4988, 2.5937,\n",
       "        2.4271, 2.5507, 2.5429, 2.4925, 2.4451, 2.3706, 2.1252, 2.2868])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68456c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.91673785)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1747742",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = np.concat(probas)\n",
    "y_true = np.concat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ac0a1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 186,   57],\n",
       "       [  74, 1203]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, probas>0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea0367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(0, 2.5), (2.5, 3), (5.5, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f32cd2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.asarray([1, 1, 1, 0, 0, 0, 1, 1])\n",
    "\n",
    "def pre_broken_barh(arr):\n",
    "    diff = np.where(np.diff(arr)!=0)[0]\n",
    "    colors = []\n",
    "    xranges = []\n",
    "\n",
    "    for i, j in enumerate(np.r_[-1, diff]):\n",
    "        colors.append(f'C{arr[j+1]}')\n",
    "        if i == 0:\n",
    "            xranges.append((0, float(diff[0])+0.5))\n",
    "            continue\n",
    "        elif i < len(diff):\n",
    "            i = float(diff[i])\n",
    "        else:\n",
    "            i = float(len(arr)-1)\n",
    "\n",
    "        j = float(j)\n",
    "        xranges.append((j+.5, i-j))\n",
    "    return xranges, colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b14da46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/pontosense/Downloads/Target/test2/ATR_GN_P2-240527-30019-2025-09-02-01-3123914-3124977_res.csv').loc[:320-1]\n",
    "df = pd.concat(\n",
    "    [df,\n",
    "    pd.read_csv('C:/Users/pontosense/Downloads/Target/test2/ATR_GN_P2-240527-30019-09-03-11-4351701-4353067_res.csv').loc[:320-1]],\n",
    "    ignore_index=True\n",
    ")\n",
    "df = pd.concat(\n",
    "    [df,\n",
    "    pd.read_csv('C:/Users/pontosense/Downloads/Target/test2/P1-TP5-0528test-185780-186966_res.csv').loc[:880-1]],\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "xranges, colors = pre_broken_barh(df['pred'].astype(int))\n",
    "ax.broken_barh(xranges,  (.2, .6), facecolors=colors)\n",
    "xranges, colors = pre_broken_barh((probas>0.8).astype(int))\n",
    "ax.broken_barh(xranges,  (1.2, .6), facecolors=colors)\n",
    "xranges, colors = pre_broken_barh(y_true.astype(int))\n",
    "ax.broken_barh(xranges,  (2.2, .6), facecolors=colors)\n",
    "\n",
    "# 设置坐标范围与样式\n",
    "ax.set_xlim(0, len(y_true))\n",
    "ax.set_ylim(-0.5, 3.5)\n",
    "ax.set_yticks([0.5, 1.5, 2.5], ['RF-PRED', 'RNN-PRED', 'GT'])\n",
    "# ax.set_xlabel(\"Time\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
